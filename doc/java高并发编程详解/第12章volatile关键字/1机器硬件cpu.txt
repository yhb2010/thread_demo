由于cpu的处理速度和内存的访问速度严重的不对等，通过传统的FSB直连内存的访问方式很明显会导致cpu资源受到大量的限制，降低了cpu整体的吞吐量，
于是就有了在cpu和主内存之间增加缓存的设计，现在缓存的数量都可以增加到3级了，最靠近cpu的缓存称为l1，然后依次是l2、l3和主内存。

cache的出现是为了解决cpu直接访问内存效率低下的问题，程序在运行过程中，会将计算所需要的数据从主存复制一份到cpu cache中，这样cpu进行
计算时就可以直接对cpu cache中的数据进行读取和写入，当运算结束之后，再将cpu cache中的最新的数据刷新到主内存当中，cpu通过直接访问cache
的方式替代直接访问主存的方式极大的提高了cpu的吞吐能力，有了cpu cache后，整体的cpu和主内存之间交互的架构大致如下：
	cpu寄存器——cpu cache——主内存ram
	
cpu缓存一致性问题：
	由于缓存的出现，极大地提高了cpu的吞吐能力，但是同时也引入了缓存不一致的问题，比如i++这个操作，在程序的运行过程中，首先需要将主内存的数
	据复制一份存放到cpu cache中，那么cpu寄存器在进行数值计算的时候就直接到cache中读取和写入，当整个过程运算结束之后再将cache中
	的数据刷新到主内存中，具体过程如下：
	1、读取主内存的i到cpu cache中
	2、对i进行加1操作
	3、将结果写回到cpu cache中
	4、将数据刷新到主内存中
	在多线程下这个会有问题，为了解决缓存不一致问题，通常主流的解决办法是：
	1、通过总线加锁的方式
	2、通过缓存一致性协议：Intel的MESI协议，该协议保证了每一个缓存中使用的共享变量副本都是一致的，它的大致意思是，当cpu在操作cache中的
	数据时，如果发现该变量是一个共享变量，也就是说在其他的cpu cache中也存在一份副本，那么进行如下操作：
	1、读取操作，不做任何处理，只是将cache中的数据读取到寄存器
	2、写入操作，发出信号通知其他cpu将该变量的cache line置为无效状态，其他cpu在进行该变量读取的时候不得不到主内存中再次获取。